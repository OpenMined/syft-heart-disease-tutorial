{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8093fc9a",
   "metadata": {},
   "source": [
    "# Train Machine learning on multiple Medical datasets\n",
    "\n",
    "In this notebook we will learn how to train Machine learning models on remote (non-public) data, using **Scikit-learn** and **PySyft**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6940ef-5525-4e70-bfb9-b42c06040e02",
   "metadata": {},
   "source": [
    "## Step 1. Login to datasites as **External Researcher**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642b926-3485-4620-a7f7-9afe2cc2634b",
   "metadata": {},
   "source": [
    "⚠️ First verify that the Datasites are already running. If needed, launch the following command in a new terminal session:\n",
    "\n",
    "```bash\n",
    "$ python launch_datasites.py\n",
    "```\n",
    "\n",
    "**Note**: In Jupyter Lab, you can open a new terminal session via `File >> New >> Terminal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c366189-de89-4a76-9375-c4cffe8e6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0657a-c5d7-46b6-a503-3709260116ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasites import DATASITE_URLS\n",
    "\n",
    "datasites = {}\n",
    "for name, url in DATASITE_URLS.items():\n",
    "    datasites[name] = sy.login(url=url, email=\"researcher@openmined.org\", password=\"****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced8378-283c-44cd-ba89-1074199e40b7",
   "metadata": {},
   "source": [
    "## Step 2. Get Mock data and test the model training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67e486-18db-4512-b503-d2272fc4a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = datasites[\"Cleveland Clinic\"].datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"].mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2366ad3-7ad7-4cfd-9f11-2061b814a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS/ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Input data is not \"ready\" for ML experiments, so we need to \n",
    "# (1) extract features and labels; (2) train/test split data \n",
    "# before training our model.\n",
    "def by_demographics(data):\n",
    "    # NO age stratification as data is too skew \n",
    "    # (see notebook 01-Compare-Demographics.ipynb)\n",
    "    sex = data[\"sex\"].map(lambda v: '0' if v == 0 else '1')\n",
    "    target = data[\"num\"].map(lambda v: '0' if v == 0 else '1')\n",
    "    return (sex+target).values\n",
    "\n",
    "# 1. get features and labels\n",
    "X = mock_data.drop(columns=[\"age\", \"sex\", \"num\"], axis=1)\n",
    "y = mock_data[\"num\"].map(lambda v: 0 if v == 0 else 1)\n",
    "# 2. partition data\n",
    "X_train, _, y_train, _ = train_test_split(\n",
    "    X, y, random_state=12345, stratify=by_demographics(mock_data)\n",
    ")\n",
    "# 3. train model: Tree-based model as its invariant to feature scale, and allows data sparsity\n",
    "model = RandomForestClassifier(random_state=12345)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2325373-76af-4428-b5c1-c970abf790c0",
   "metadata": {},
   "source": [
    "## Step 3. Submit Experiment to each datasite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36b59f-2236-4a07-bd3d-dd34cee62cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, datasite in datasites.items():\n",
    "    print(f\"Datasite: {name}\")\n",
    "    # 1. Get data asset from datasite\n",
    "    data_asset = datasite.datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"]\n",
    "    \n",
    "    @sy.syft_function_single_use(data=data_asset)\n",
    "    def train(data):\n",
    "        # DS/ML libraries\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        # Extra dependencies for model persistance (see 4.)\n",
    "        import joblib\n",
    "        from io import BytesIO\n",
    "        \n",
    "        def by_demographics(data):\n",
    "            sex = data[\"sex\"].map(lambda v: '0' if v == 0 else '1')\n",
    "            target = data[\"num\"].map(lambda v: '0' if v == 0 else '1')\n",
    "            return (sex+target).values\n",
    "        \n",
    "        # 1. get features and labels\n",
    "        X = data.drop(columns=[\"age\", \"sex\", \"num\"], axis=1)\n",
    "        y = data[\"num\"].map(lambda v: 0 if v == 0 else 1)\n",
    "        # 2. partition data\n",
    "        X_train, _, y_train, _ = train_test_split(\n",
    "            X, y, random_state=12345, stratify=by_demographics(data)\n",
    "        )\n",
    "        # 3. train model\n",
    "        model = RandomForestClassifier(random_state=12345)\n",
    "        model.fit(X_train, y_train)\n",
    "        # 4. model persistance - return model serialised \n",
    "        serialised_model = BytesIO()\n",
    "        joblib.dump(model, serialised_model)\n",
    "\n",
    "        return serialised_model\n",
    "    \n",
    "    ml_training_project = sy.Project(\n",
    "        name=\"Traning RandomForest Classifier on Heart Study Data\",\n",
    "        description=\"\"\"I would like to train a classifier on the Heart Study data.\n",
    "        The code will partition the dataset using sex and target, and will train \n",
    "        a RandomForest classifier, that will be returned serialised.\n",
    "        \"\"\",\n",
    "        members=[datasite],\n",
    "    )\n",
    "    ml_training_project.create_code_request(train, datasite)\n",
    "    project = ml_training_project.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a4550-328c-4519-a1e3-e5fa0376f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_status_last_code_requests\n",
    "\n",
    "check_status_last_code_requests(datasites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09fc91-fecb-4ef7-b928-18941ecfda4e",
   "metadata": {},
   "source": [
    "## Step 4. Train Models on all datasites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707f236-993c-4b17-b5f1-d8a7dc5ef9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dump_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020ffc1-879b-4183-8f8d-0189badf1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, datasite in datasites.items():\n",
    "    print(f\"Datasite: {name}\")\n",
    "    data_asset = datasite.datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"]\n",
    "    serialised_model = datasite.code.train(data=data_asset).get_from(datasite)\n",
    "    print(dump_model(datasite_name=name, model_buffer=serialised_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfdbb3-9bc4-4956-a97c-4936dfd0978b",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We have trained and stored independently **four** Random Forest Classifiers, using the (non-public) data in each hospital, and <u>_without seeing nor downloading the training data_</u>! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
