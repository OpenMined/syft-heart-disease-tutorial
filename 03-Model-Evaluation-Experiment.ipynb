{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7884ec0c",
   "metadata": {},
   "source": [
    "# Evaluate Machine learning performance on non-public Medical data\n",
    "\n",
    "In this notebook we will learn how to assess ML model performance, using test data as gathered on each Datasite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63069b93-f499-47f1-be75-250d8a47ee52",
   "metadata": {},
   "source": [
    "## Step 1. Login to datasites as **External Researcher**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c80f-0152-4a4f-9492-a57d777f09e1",
   "metadata": {},
   "source": [
    "âš ï¸ First verify that the Datasites are already running. If needed, launch the following command in a new terminal session:\n",
    "\n",
    "```bash\n",
    "$ python launch_datasites.py\n",
    "```\n",
    "\n",
    "**Note**: In Jupyter Lab, you can open a new terminal session via `File >> New >> Terminal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7c76c-44a8-48df-b119-51fe15fce119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c35765-b52b-4bb8-a291-0cc4476bdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasites import DATASITE_URLS\n",
    "\n",
    "datasites = {}\n",
    "for name, url in DATASITE_URLS.items():\n",
    "    datasites[name] = sy.login(url=url, email=\"researcher@openmined.org\", password=\"****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ad8f1-c0ee-4107-8376-625b506d12c7",
   "metadata": {},
   "source": [
    "## Step 2. Get Mock data and test the model evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40bb1b9-7f26-4d3c-aa0f-d491b1edb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = datasites[\"Cleveland Clinic\"].datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"].mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904889bd-d7e3-468c-9a04-0aabda68cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS/ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef as mcc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import load_model  # utility function to load stored trained models from disk\n",
    "\n",
    "\n",
    "# ML Data preparation - same strategy as in 02-Model-Training-Experiment.ipynb\n",
    "def by_demographics(data):\n",
    "    sex = data[\"sex\"].map(lambda v: '0' if v == 0 else '1')\n",
    "    target = data[\"num\"].map(lambda v: '0' if v == 0 else '1')\n",
    "    return (sex+target).values\n",
    "\n",
    "# 1. get features and labels\n",
    "X = mock_data.drop(columns=[\"age\", \"sex\", \"num\"], axis=1)\n",
    "y = mock_data[\"num\"].map(lambda v: 0 if v == 0 else 1)\n",
    "# 2. partition data\n",
    "_, X_test, _, y_test = train_test_split(\n",
    "    X, y, random_state=12345, stratify=by_demographics(mock_data)\n",
    ")\n",
    "# 3. Load a single trained model as example\n",
    "model_dump_file = \"./models/cleveland_clinic_model.jbl\"\n",
    "classifier = load_model(model_dump_file)\n",
    "# 4. Evaluate Metrics (MCC score and Confusion Matrix)\n",
    "y_pred = classifier.predict(X_test)\n",
    "mcc_test = mcc_score(y_test, y_pred)  # count both positives and negatives\n",
    "cm = confusion_matrix(y_test, y_pred) # compare performance across classes\n",
    "print(mcc_test)  # should be almost zero as it's random data! MCC ranges from -1 to 1\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4490aa-4f32-4cb2-908d-d121dedd9aa1",
   "metadata": {},
   "source": [
    "## Step 3. Submit Experiment to each datasite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9a5c6-d5a7-454b-81c5-da8c0522721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model files\n",
    "from utils import load_models\n",
    "# Load saved models from disk\n",
    "models = load_models(datasites)\n",
    "assert len(models) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f51aa-c44a-46af-85d0-96c09cd28b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import serialize_and_upload\n",
    "remote_models = {}\n",
    "\n",
    "for name, datasite in datasites.items():\n",
    "    print(f\"Datasite: {name}\")\n",
    "    # 1. Get data asset from datasite\n",
    "    data_asset = datasite.datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"]\n",
    "    # 1.1 Upload models to Datasite (to be passed as input of the Syft function)\n",
    "    remote_model = serialize_and_upload(model=models[name], to=datasite)\n",
    "    remote_models[name] = remote_model\n",
    "    \n",
    "    @sy.syft_function_single_use(data=data_asset, model=remote_model)\n",
    "    def evaluate(data, model):\n",
    "        # DS/ML libraries\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import matthews_corrcoef as mcc_score\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import joblib  # to load serialised input model\n",
    "        \n",
    "        # ML Data preparation - same strategy as in model training\n",
    "        def by_demographics(data):\n",
    "            sex = data[\"sex\"].map(lambda v: '0' if v == 0 else '1')\n",
    "            target = data[\"num\"].map(lambda v: '0' if v == 0 else '1')\n",
    "            return (sex+target).values\n",
    "        \n",
    "        # 1. get features and labels\n",
    "        X = data.drop(columns=[\"age\", \"sex\", \"num\"], axis=1)\n",
    "        y = data[\"num\"].map(lambda v: 0 if v == 0 else 1)\n",
    "        # 2. partition data\n",
    "        _, X_test, _, y_test = train_test_split(\n",
    "            X, y, random_state=12345, stratify=by_demographics(data)\n",
    "        )\n",
    "        # 3. Get trained model\n",
    "        classifier = joblib.load(model)  # load model\n",
    "        # 4. Evaluate Metrics (MCC and Confusion Matrix)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        return mcc_score(y_test, y_pred), confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    ml_eval_project = sy.Project(\n",
    "        name=\"Evaluate performance of trained classifier on Heart Study Data\",\n",
    "        description=\"\"\"I would like to calculate MCC score, and Confusion Matrix on the test data partition for the \n",
    "         input trained RandomForest classifier.\"\"\",\n",
    "        members=[datasite],\n",
    "    )\n",
    "    ml_eval_project.create_code_request(evaluate, datasite)\n",
    "    project = ml_eval_project.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f1236-7b47-446a-9300-64aa580ccbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_status_last_code_requests\n",
    "\n",
    "check_status_last_code_requests(datasites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e094824e-9fc1-4d35-b504-678c432edb7b",
   "metadata": {},
   "source": [
    "## Step 4. Evaluate Models on all datasites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9b106-9684-4442-8326-30bbabcf06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_scores, confusion_matrices = {}, {}\n",
    "for name, datasite in datasites.items():\n",
    "    print(f\"Datasite: {name}\")\n",
    "    data_asset = datasite.datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"]\n",
    "    remote_model = remote_models[name]\n",
    "    results = datasite.code.evaluate(data=data_asset, model=remote_model).get_from(datasite)\n",
    "    mcc_scores[name], confusion_matrices[name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aecc97-4663-4cd4-a8cc-c69deb60746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505ebf2-25a0-4c8c-9208-4ffbbad74e62",
   "metadata": {},
   "source": [
    "Data is so skew (as expected) in the 'Univ. Hospitals Zurich and Basel' that the model is basically predicting always the same outcome (i.e. `MCC = 0`).\n",
    "\n",
    "Let's double check the resulting confusion matrices, and then will see if we can do better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21f9ac-d250-44d3-8630-b77d3ec57631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from utils import plot_all_confusion_matrices\n",
    "\n",
    "plot_all_confusion_matrices(confusion_matrices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206e66e-5c9d-426a-844c-13e43853934b",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We have gathered evaluation metrics (MCC and Confusion Matrix) for each trained `RandomForestClassifier` model, using test data on each corresponding datasite. In addition to running our code on the non-public data, in this notebook we have learnt how to upload an ML model to a datasite, to be used in a Syft function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7feb48-1736-4042-9d0a-ce09dba0d943",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "As an exercise, you could try to check model performance using _test data_ gathered from datasites different than the ones used in training!\n",
    "\n",
    "> ðŸ’¡ Considering the code of our experiment, the only thing you'd need to change is _which_ model gets passed in as input to the `evaluate` function! ðŸ˜‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
