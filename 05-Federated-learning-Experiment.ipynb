{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d3d7d7-857c-40e5-94f3-052d046b0b80",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "> *You made it to part 5! You're absolutely* ***crushing it*** ðŸš€ âœ¨\n",
    ">\n",
    "> **Keep going!** The best is yet to come!\n",
    ">\n",
    "> *Valerio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad9e42-c449-4487-ba66-0f379a25e4fc",
   "metadata": {},
   "source": [
    "# Federated learning with PySyft\n",
    "\n",
    "In this notebook we will learn how to run a Federated Learning experiment, using **Scikit-learn** and **PySyft**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e95d51-313e-4ddb-9340-5e3de0e82bc0",
   "metadata": {},
   "source": [
    "## Step 1. Login to datasites as **External Researcher**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167121f-90cc-4bbc-8e15-0e8e56160302",
   "metadata": {},
   "source": [
    "âš ï¸ First verify that the Datasites are already running. If needed, launch the following command in a new terminal session:\n",
    "\n",
    "```bash\n",
    "$ python launch_datasites.py\n",
    "```\n",
    "\n",
    "**Note**: In Jupyter Lab, you can open a new terminal session via `File >> New >> Terminal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a3ee2-7a98-427c-8098-30d724e43be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283e48c-9d97-42f4-a905-64436ed24a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasites import DATASITE_URLS\n",
    "\n",
    "datasites = {}\n",
    "for name, url in DATASITE_URLS.items():\n",
    "    datasites[name] = sy.login(url=url, email=\"researcher@openmined.org\", password=\"****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a701372-0aca-4379-a50f-62ed76d81b39",
   "metadata": {},
   "source": [
    "## Step 2. Get Mock data and test the code for the Machine Learning (`ML`) experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327de04-6548-4936-b525-04475a65f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = datasites[\"Cleveland Clinic\"].datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"].mock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470655e4-400e-49cd-9356-89455c45120f",
   "metadata": {},
   "source": [
    "**TYPE ANNOTATIONS**\n",
    "\n",
    "Most of the complexity with this example lies in the `ml_experiment` implementation, especially for what concern data preparation as we need to take care of data sparsity, and missing values to use our ML model. \n",
    "For this reason, let's use some Python type annotations to better document the input/output of each step in our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579987e-e01c-454a-9092-955ce8a5bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import Union, TypeVar, Any\n",
    "\n",
    "DataFrame = TypeVar(\"pandas.DataFrame\")\n",
    "NDArray = npt.NDArray[Any]\n",
    "NDArrayInt = npt.NDArray[np.int_]\n",
    "NDArrayFloat = npt.NDArray[np.float_]\n",
    "\n",
    "Dataset = TypeVar(\"Dataset\", bound=tuple[NDArrayFloat, NDArrayInt])\n",
    "Metric = TypeVar(\"Metric\", bound=dict[str, Union[float, NDArrayInt]])\n",
    "Metrics = TypeVar(\"Metrics\", bound=tuple[Metric, Metric])  # train and test\n",
    "ModelParams = TypeVar(\"ModelParams\", bound=dict[str, NDArrayFloat])\n",
    "Result = TypeVar(\"Result\", bound=tuple[Metrics, ModelParams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74dea8-dff5-4c68-8ea3-fee065b3512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_experiment(data: DataFrame, model_params: ModelParams = None) -> Result:\n",
    "    \"\"\"ML Experiment using a PassiveAggressive (linear) Classifier.\n",
    "    Steps:\n",
    "    1. Preprocessing (partitioning; missing values & scaling)\n",
    "    2. Model setup (w/ `model_params`)\n",
    "    3. Training: gather updated model parameters\n",
    "    4. Evaluation: collect metrics on training and test partitions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        Input Heart Study data represented as Pandas DataFrame.\n",
    "    model_params: ModelParams (dict)\n",
    "        DL Model Parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : Metrics\n",
    "        Evaluation metrics (i.e. MCC, Confusion matrix) on both training and test\n",
    "        data partitions.\n",
    "    model_params : ModelParams\n",
    "        Update model params after training.\n",
    "    \"\"\"\n",
    "    # preprocessing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "    # training (model)\n",
    "    from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "    # evaluation (metrics)\n",
    "    from sklearn.metrics import matthews_corrcoef as mcc\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "        \n",
    "    def preprocess(data: DataFrame) -> tuple[Dataset, Dataset]:\n",
    "\n",
    "        def by_demographics(data: DataFrame) -> NDArray:\n",
    "            sex = data[\"sex\"].map(lambda v: \"0\" if v == 0 else \"1\")\n",
    "            target = data[\"num\"].map(lambda v: \"0\" if v == 0 else \"1\")\n",
    "            return (sex + target).values\n",
    "\n",
    "        X = data.drop(columns=[\"age\", \"sex\", \"num\"], axis=1)\n",
    "        y = data[\"num\"].map(lambda v: 0 if v == 0 else 1)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, random_state=12345, stratify=by_demographics(data))\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[(\"numerical\",\n",
    "                           Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                                           (\"scaler\", RobustScaler()),]),\n",
    "                           [\"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]),\n",
    "                          (\"categorical\", \n",
    "                           SimpleImputer(strategy=\"most_frequent\",),\n",
    "                           [\"ca\", \"cp\", \"exang\", \"fbs\", \"restecg\", \"slope\", \"thal\"])])\n",
    "        X_train = preprocessor.fit_transform(X_train)\n",
    "        X_test = preprocessor.transform(X_test)\n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "    def train(model, training_data: Dataset) -> ModelParams:\n",
    "        X_train, y_train = training_data\n",
    "        model.fit(X_train, y_train)\n",
    "        return {\"intercept\": model.intercept_, \"coefs\": model.coef_}\n",
    "\n",
    "    def evaluate(model, data: Dataset) -> Metric:\n",
    "        X, y_true = data\n",
    "        y_pred = model.predict(X)\n",
    "        return {\"mcc\": mcc(y_true, y_pred), \"cm\": confusion_matrix(y_true, y_pred)}\n",
    "\n",
    "    # -- ML Experiment --\n",
    "    # 1. preprocessing\n",
    "    training_data, test_data = preprocess(data)\n",
    "    # 2. model setup\n",
    "    clf = PassiveAggressiveClassifier(random_state=12345, warm_start=True)\n",
    "    if model_params:\n",
    "        clf.classes_ = [0, 1]\n",
    "        clf.intercept_ = model_params[\"intercept\"]\n",
    "        clf.coef_ = model_params[\"coefs\"]\n",
    "    # 3. training\n",
    "    model_params = train(clf, training_data)\n",
    "    # 4. evaluation\n",
    "    training_metrics = evaluate(clf, training_data)\n",
    "    test_metrics = evaluate(clf, test_data)\n",
    "    return (training_metrics, test_metrics), model_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc84af-273f-4d25-88b4-0e441fbf24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, model_params = ml_experiment(data=mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec11f5f-20a7-4107-81c3-108b92eb5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d4c44-b0b6-4408-9912-12166c0b5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46524e-a024-4a04-bf3e-e2261bb19e1c",
   "metadata": {},
   "source": [
    "## Step 3. FL Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b7221-1884-4e23-bdf0-42c9a63ca6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.service.policy.policy import MixedInputPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d38504-f48e-4e27-bbd4-9e10f90ac1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, datasite in datasites.items():\n",
    "    data_asset = datasite.datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"]\n",
    "    syft_fl_experiment = sy.syft_function(\n",
    "        input_policy=MixedInputPolicy(\n",
    "            client=datasite, data=data_asset, model_params=dict\n",
    "        )\n",
    "    )(ml_experiment)\n",
    "    ml_training_project = sy.Project(\n",
    "        name=\"ML Experiment for FL\",\n",
    "        description=\"\"\"I would like to run this ML experiment on Heart Disease data, to be used in a Federated Learning fashion. \n",
    "        The function will iteratively receive an input dictionary containing the average model parameters \n",
    "        resulting from the FL experiment iteration on all the four Hospitals datasites.\n",
    "        Training and Test metrics will be returned after each run to monitor the learning progress.\"\"\",\n",
    "        members=[datasite],\n",
    "    )\n",
    "    ml_training_project.create_code_request(syft_fl_experiment, datasite)\n",
    "    project = ml_training_project.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b6a9a-bae5-4351-afde-6b762f8d57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_status_last_code_requests\n",
    "\n",
    "check_status_last_code_requests(datasites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da23a8f-b1ef-4f54-a709-2442a824f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d229147-a0f0-4bdf-b5c8-e553323a1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(all_models_params: list[ModelParams]) -> ModelParams: \n",
    "    return {\"intercept\": np.average([p[\"intercept\"] for p in all_models_params], axis=0), \n",
    "            \"coefs\": np.average([p[\"coefs\"] for p in all_models_params], axis=0)}\n",
    "\n",
    "def fl_experiment(datasites: dict[str, sy.DatasiteClient], fl_epochs: int = 15):\n",
    "    fl_model_params, fl_metrics = dict(), defaultdict(list)  # one entry per epoch as a list\n",
    "    for epoch in range(fl_epochs):\n",
    "        for datasite in datasites.values():\n",
    "            data_asset = datasite.datasets[\"Heart Disease Dataset\"].assets[\"Heart Study Data\"]\n",
    "            metrics, params = datasite.code.ml_experiment(data=data_asset, model_params=fl_model_params).get_from(datasite)\n",
    "            fl_metrics[epoch].append((metrics, params))\n",
    "        fl_model_params = avg([params for _, params in fl_metrics[epoch]])\n",
    "    return fl_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647c1af-b810-4a83-8c40-60223b574af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_metrics = fl_experiment(datasites, fl_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a61324-ed24-43cc-9c01-f8c1372399b9",
   "metadata": {},
   "source": [
    "## Step 4. Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa500cc-fbc0-4eba-950e-de2aa496e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from utils import plot_fl_metrics\n",
    "\n",
    "plot_fl_metrics(datasites, fl_metrics, title=\"FL Experiment on Heart Disease Data w/ PassiveAggressive (Linear) Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe612ed5-0549-480e-a23f-79723c681fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_all_confusion_matrices\n",
    "\n",
    "last_epoch = sorted(fl_metrics)[-1]\n",
    "confusion_matrices = {name: fl_metrics[last_epoch][idx][0][1][\"cm\"] for idx, name in enumerate(datasites)}\n",
    "plot_all_confusion_matrices(confusion_matrices, title=\"Confusion Matrices of FL PassiveAggressive Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e59739-8e38-41f7-bb05-da81d017ba85",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "_complete_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
